@book{prince_medical_2014,
	isbn = {9780132145183},
	year = {2015},
	title = {Medical Imaging: Signals And Systems},
	edition = {2},
	language = {eng},
	author = {Prince, Jerry L.},
}

@book{buzug_computed_2008,
	isbn = {9783540394075},
	year = {2008},
	title = {Computed Tomography: From Photon Statistics to Modern Cone-Beam CT},
	language = {eng},
	author = {Buzug, Thorsten M},
	keywords = {Tomography},
}

@book{morneburg_bildgebende_1995,
	title = {Bildgebende Systeme für die medizinische Diagnostik: Röntgendiagnostik und Angiographie, Computertomographie, Nuklearmedizin, Magnetresonanztomographie, Sonographie, integrierte Informationssysteme},
	author = {Morneburg, H. and {Siemens Aktiengesellschaft}},
	isbn = {9783895780028},
	url = {https://books.google.at/books?id=1DDPGgAACAAJ},
	year = {1995},
	publisher = {Publicis MCD Verlag}
}

@article{siewerdsen_influence_2004,
	author = {Siewerdsen, J. H. and Moseley, D. J. and Bakhtiar, B. and Richard, S. and Jaffray, D. A.},
	title = {The Influence of Antiscatter Grids on Soft-Tissue Detectability in Cone-Beam Computed Tomography with Flat-Panel Detectors},
	journal = {Medical Physics},
	volume = {31},
	number = {12},
	pages = {3506-3520},
	keywords = {Computed radiography, Imaging detectors and sensors, Image analysis, Image quality, computerised tomography, X-ray scattering, phantoms, image reconstruction, image resolution, medical image processing, image sensors, biological organs, biological tissues, flat-panel imager, computed tomography, cone-beam CT, imaging performance, x-ray scatter, artifacts, antiscatter grid, scatter correction, image-guided procedures, Medical imaging, Medical image noise, Medical X-ray imaging, X-ray scattering, Computed tomography, Cone beam computed tomography, Medical image artifacts, Medical image quality, Image sensors, Medical image reconstruction},
	doi = {10.1118/1.1819789},
	url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.1819789},
	eprint = {https://aapm.onlinelibrary.wiley.com/doi/pdf/10.1118/1.1819789},
	abstract = {The influence of antiscatter x-ray grids on image quality in cone-beam computed tomography (CT) is evaluated through broad experimental investigation for various anatomical sites (head and body), scatter conditions (scatter-to-primary ratio (SPR) ranging from to 150\%), patient dose, and spatial resolution in three-dimensional reconstructions. Studies involved linear grids in combination with a flat-panel imager on a system for kilovoltage cone-beam CT imaging and guidance of radiation therapy. Grids were found to be effective in reducing x-ray scatter artifacts, with heavier grids providing increased image uniformity. The system was highly robust against ring artifacts that might arise in CT reconstructions as a result of gridline shadows in the projection data. The influence of grids on soft-tissue detectability was evaluated quantitatively in terms of absolute contrast, voxel noise, and contrast-to-noise ratio (CNR) in cone-beam CT reconstructions of and cylindrical phantoms. Imaging performance was investigated qualitatively in observer preference tests based on patient images (pelvis, abdomen, and head-and-neck sites) acquired with and without antiscatter grids. The results suggest that although grids reduce scatter artifacts and improve subject contrast, there is little strong motivation for the use of grids in cone-beam CT in terms of CNR and overall image quality under most circumstances. The results highlight the tradeoffs in contrast and noise imparted by grids, showing improved image quality with grids only under specific conditions of high x-ray scatter , high imaging dose , and low spatial resolution (voxel size).},
	year = {2004}
}

@inbook{klein_scattering_1994,
	author = {Klein, O. and Nishina, Y.},
	title = {On the Scattering of Radiation by Free Electrons According to Dirac's New Relativistic Quantum Dynamics},
	booktitle = {The Oskar Klein Memorial Lectures},
	chapter = {},
	year = {1994},
	pages = {113-129},
	doi = {10.1142/9789814335911_0006},
	URL = {https://www.worldscientific.com/doi/abs/10.1142/9789814335911_0006},
	eprint = {https://www.worldscientific.com/doi/pdf/10.1142/9789814335911_0006},
	abstract = { Abstract The intensity of Compton scattering radiation is calculated on the basis of the new relativistic quantum dynamics developed by Dirac. The result shows deviations from the corresponding Dirac—Gordon formulae of second order with respect to the ratio of the energy of the primary light quantum to the rest energy of the electron. }
}

@book{wolbarst_physics_2005,
	title = {Physics of Radiology},
	author = {Wolbarst, A. B.},
	isbn = {9781930524224},
	lccn = {2004049923},
	url = {https://books.google.at/books?id=nlhQPgAACAAJ},
	year = {2005},
	publisher = {Medical Physics Pub.}
}

@book{johns_physics_2014,
	title = {The Physics of Radiology},
	author = {Johns, H. E. and Cunningham, J. R.},
	isbn = {9780398090166},
	url = {https://books.google.at/books?id=RKlPAQAACAAJ},
	year = {2014},
	publisher = {Charles C. Thomas Publisher, Limited}
}

@book{bracewell_fourier_1986,
	title = {The Fourier Transform and Its Applications},
	author = {Bracewell, R. N.},
	isbn = {9780070070165},
	lccn = {85023774},
	series = {McGraw-Hill Series in Electrical Engineering},
	url = {https://books.google.at/books?id=WhSGngEACAAJ},
	year = {1986},
	publisher = {McGraw-Hill}
}

@book{magnusson_linogram_1993,
	title = {Linogram and Other Direct Fourier Methods for Tomographic Reconstruction},
	author = {Magnusson, M.},
	year = {1993},
}

@article{schumacher_flexible_2007,
	title = {A New Flexible Reconstruction Framework for Motion Correction in SPECT Imaging},
	author = {Schumacher, H. and Fischer, B.},
	journal = {IEEE Transactions on Nuclear Science},
	year = {2007},
	volume = {54},
	pages = {480-485}
}

@article{rit_motion_2009,
	author = {Rit, Simon and Wolthaus, Jochem W. H. and van Herk, Marcel and Sonke, Jan-Jakob},
	title = {On-the-fly Motion-Compensated Cone-Beam CT Using an A-priori Model of the Respiratory Motion},
	journal = {Medical Physics},
	volume = {36},
	number = {6Part1},
	pages = {2283-2296},
	keywords = {Reconstruction, Computed tomography, Artifacts and distortion, Noise, computerised tomography, image denoising, image reconstruction, medical image processing, motion compensation, motion estimation, motion compensation, image guided radiation therapy, cone-beam CT, organ motion, reconstruction, Medical imaging, Cone beam computed tomography, Medical image reconstruction, Computed tomography, Medical image quality, Cancer, Medical image noise, Medical image artifacts, Lungs, Motion estimation},
	doi = {10.1118/1.3115691},
	url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.3115691},
	eprint = {https://aapm.onlinelibrary.wiley.com/doi/pdf/10.1118/1.3115691},
	abstract = {Respiratory motion causes artifacts in cone-beam (CB) CT images acquired on slow rotating scanners integrated with linear accelerators. Respiration-correlated CBCT has been proposed to correct for the respiratory motion but only a subset of the CB projections is used to reconstruct each frame of the 4D CBCT image and, therefore, adequate image quality requires long acquisition times. In this article, the authors develop an on-the-fly solution to estimate and compensate for the respiratory motion in the reconstruction of a 3D CBCT image from all the CB projections. An a priori motion model of the patient respiratory cycle is estimated from the 4D planning CT. During the acquisition, the model is correlated with the respiration using a respiratory signal extracted from the CB projections. The estimated motion is next compensated for in an optimized reconstruction algorithm. The motion compensated for is forced to be null on average over the acquisition time to ensure that the compensation results in a CBCT image which describes the mean position of each organ, even if the a priori motion model is inaccurate. Results were assessed on simulated, phantom, and patient data. In all experiments, blur was visually reduced by motion-compensated CBCT. Simulations showed robustness to inaccuracies of the motion model observed on patient data such as amplitude variations, phase shifts, and setup errors, thus proving the efficiency of the compensation using an a priori motion model. Noise and view-aliasing artifacts were lower on motion-compensated CBCT images with 1 min scan than on respiration-correlated CBCT images with 4 min scan. Finally, on-the-fly motion estimation and motion-compensated reconstruction were within the acquisition time of the CB projections and the CBCT image available a few seconds after the end of the acquisition. In conclusion, the authors developed and implemented a method for correcting the respiratory motion during the treatment fractions which can replace respiration-correlated CBCT for improving image quality while decreasing acquisition time.},
	year = {2009}
}

@article {ramachandran_reconstruction_1971,
	author = {Ramachandran, G. N. and Lakshminarayanan, A. V.},
	title = {Three-dimensional Reconstruction from Radiographs and Electron Micrographs: Application of Convolutions instead of Fourier Transforms},
	volume = {68},
	number = {9},
	pages = {2236--2240},
	year = {1971},
	doi = {10.1073/pnas.68.9.2236},
	publisher = {National Academy of Sciences},
	abstract = {A new technique is proposed for the mathematical process of reconstruction of a three-dimensional object from its transmission shadowgraphs; it uses convolutions with functions defined in the real space of the object, without using Fourier transforms. The object is rotated about an axis at right angles to the direction of a parallel beam of radiation, and sections of it normal to the axis are reconstructed from data obtained by scanning the corresponding linear strips in the shadowgraphs at different angular settings.Since the formulae in the convolution method involve only summations over one variable at a time, while a two-dimensional reconstruction with the Fourier transform technique requires double summations, the convolution method is much faster (typically by a factor of 30); the relative increase in speed is larger where greater resolution is required. Tests of the convolution method with computer-simulated shadowgraphs show that it is also more accurate than the Fourier transform method. It has good potentialities for application in electron microscopy and x-radiography. A new method of reconstructing helical structures by this technique is also suggested.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/68/9/2236},
	eprint = {https://www.pnas.org/content/68/9/2236.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}

@article{radon_bestimmung_1917,
	added-at = {2010-08-20T12:09:24.000+0200},
	author = {Radon, J.},
	biburl = {https://www.bibsonomy.org/bibtex/2b0128caaef39bf1265503f99b560dbfb/haggis79},
	interhash = {fdcf4d741dfedba3c56a3a942ecc463b},
	intrahash = {b0128caaef39bf1265503f99b560dbfb},
	journal = {Berichte über die Verhandlungen der Königlich-Sächsischen Akademie der Wissenschaften zu Leipzig, Mathematisch-Physische Klasse},
	keywords = {imported},
	owner = {schohaad},
	pages = {262-277},
	timestamp = {2010-08-20T12:09:25.000+0200},
	title = {Über die Bestimmung von Funktionen durch ihre Integralwerte längs gewisser Mannigfaltigkeiten},
	volume = {69},
	year = {1917}
}

@Inbook{nolet_seismic_1987,
	author = {Nolet, G.},
	editor = {Nolet, Guust},
	title = {Seismic Wave Propagation and Seismic Tomography},
	bookTitle = {Seismic Tomography: With Applications in Global Seismology and Exploration Geophysics},
	year = {1987},
	publisher = {Springer Netherlands},
	address = {Dordrecht},
	pages = {1--23},
	abstract = {This chapter develops the basic principles of seismic tomography and serves as a general introduction to this book.},
	isbn = {978-94-009-3899-1},
	doi = {10.1007/978-94-009-3899-1_1},
	url = {https://doi.org/10.1007/978-94-009-3899-1_1}
}

@article{borozdin_cosmic_2012,
	title = {Cosmic Ray Radiography of the Damaged Cores of the Fukushima Reactors},
	author = {Borozdin, Konstantin and Greene, Steven and Luki\ifmmode \acute{c}\else \'{c}\fi{}, Zarija and Milner, Edward and Miyadera, Haruo and Morris, Christopher and Perry, John},
	journal = {Physical Review Letters},
	volume = {109},
	issue = {15},
	pages = {152501},
	numpages = {3},
	year = {2012},
	month = {10},
	publisher = {American Physical Society},
	doi = {10.1103/PhysRevLett.109.152501},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.109.152501}
}

@article{sungsoo_lookup_2017,
	author = {Ha, Sungsoo and Mueller, Klaus},
	year = {2017},
	month = {08},
	pages = {1-1},
	title = {A Look-Up Table-Based Ray Integration Framework for 2-D/3-D Forward and Back Projection in X-Ray CT},
	volume = {PP},
	journal = {IEEE Transactions on Medical Imaging},
	doi = {10.1109/TMI.2017.2741781}
}

@book{blanck_understanding_1998,
	isbn = {9780683303049},
	year = {1998},
	title = {Understanding Helical Scanning},
	language = {eng},
	author = {Blanck, Cheryl A.},
	keywords = {Tomography},
}

@InProceedings{grangeat_mathematical_1991,
	author = {Grangeat, Pierre},
	editor = {Herman, Gabor T.  and Louis, Alfred K.  and Natterer, Frank},
	title = {Mathematical Framework of Cone-Beam 3D Reconstruction via the First Derivative of the Radon Transform},
	booktitle = {Mathematical Methods in Tomography},
	year = {1991},
	publisher = {Springer Berlin Heidelberg},
	address = {Berlin, Heidelberg},
	pages = {66--97},
	abstract = {Either for medical imaging or for non destructive testing, X-ray provides a very accurate mean to investigate internal structures. The object is described by a 3D map f of the local density. The use of a 2D X-ray detector like an image intensifier in front of the ponctual X-ray source defines a cone beam geometry. When the source moves along a curve, the acquisition measurements are modelized by the cone beam X-ray transform of the function f. This same model can be applied to emission tomography when cone beam collimators are used.},
	isbn = {978-3-540-46615-4}
}

@ARTICLE{kudo_derivation_1994,
	author = {Kudo, H. and Saito, T.},
	journal = {IEEE Transactions on Medical Imaging},
	title = {Derivation and Implementation of a Cone-Beam Reconstruction Algorithm for Nonplanar Orbits},
	year = {1994},
	volume = {13},
	number = {1},
	pages = {196-211},
	doi = {10.1109/42.276158}
}

@ARTICLE{defrise_cone_1994,
	author = {Defrise, M. and Clack, R.},
	journal = {IEEE Transactions on Medical Imaging},
	title = {A Cone-Beam Reconstruction Algorithm using Shift-Variant Filtering and Cone-Beam Backprojection},
	year = {1994},
	volume = {13},
	number = {1},
	pages = {186-195},
	doi = {10.1109/42.276157}
}

@article{feldkamp_practical_1984,
	author = {Feldkamp, L. A. and Davis, L. C. and Kress, J. W.},
	journal = {Journal of the Optical Society of America A},
	keywords = {Detector arrays; Image intensifiers; Reconstruction algorithms; Scanners; Three dimensional reconstruction; X ray imaging},
	number = {6},
	pages = {612--619},
	publisher = {OSA},
	title = {Practical Cone-Beam Algorithm},
	volume = {1},
	month = {6},
	year = {1984},
	url = {http://josaa.osa.org/abstract.cfm?URI=josaa-1-6-612},
	doi = {10.1364/JOSAA.1.000612},
	abstract = {A convolution-backprojection formula is deduced for direct reconstruction of a three-dimensional density function from a set of two-dimensional projections. The formula is approximate but has useful properties, including errors that are relatively small in many practical instances and a form that leads to convenient computation. It reduces to the standard fan-beam formula in the plane that is perpendicular to the axis of rotation and contains the point source. The algorithm is applied to a mathematical phantom as an example of its performance.},
}

@ARTICLE{zhu_scatter_2006,
	author = {Zhu, L. and Bennett, N. R. and Fahrig, R.},
	journal = {IEEE Transactions on Medical Imaging}, 
	title = {Scatter Correction Method for X-Ray CT Using Primary Modulation: Theory and Preliminary Results},
	year = {2006},
	volume = {25},
	number = {12},
	pages = {1573-1587},
	doi = {10.1109/TMI.2006.884636}
}

@article{brenner_computed_2007,
	doi = {10.1056/nejmra072149},
	url = {https://doi.org/10.1056/nejmra072149},
	year = {2007},
	month = {11},
	publisher = {Massachusetts Medical Society},
	volume = {357},
	number = {22},
	pages = {2277--2284},
	author = {Brenner, David J. and Hall, Eric J.},
	title = {Computed Tomography {\textemdash} An Increasing Source of Radiation Exposure},
	journal = {New England Journal of Medicine}
}

@article{yu_radiation_2009,
	doi = {10.2217/iim.09.5},
	url = {https://doi.org/10.2217/iim.09.5},
	year = {2009},
	month = {10},
	publisher = {{OMICS} Publishing Group},
	volume = {1},
	number = {1},
	pages = {65--84},
	author = {Yu, Lifeng and Liu, Xin and Leng, Shuai and Kofler, James M. and Ramirez-Giraldo, Juan C. and Qu, Mingliang and Christner, Jodie and Fletcher, Joel G. and McCollough, Cynthia H},
	title = {Radiation Dose Reduction in Computed Tomography: Techniques and Future Perspective},
	journal = {Imaging in Medicine}
}

@book{ncrp_ionizing_2009,
	author = {{National Council of Radiation Protection and Measurements}},
	title = {Ionising radiation exposure of the population of the United States},
	year = {2009},
	month = {08},
	publisher = {{OMICS} Publishing Group},
}

@ARTICLE{donoho_compressed_2006,
	author = {Donoho, D. L.},
	journal = {IEEE Transactions on Information Theory},
	title = {Compressed Sensing},
	year = {2006},
	volume = {52},
	number = {4},
	pages = {1289-1306},
	doi = {10.1109/TIT.2006.871582}
}

@article{chen_sparsect_2019,
	doi = {10.1002/mp.13544},
	url = {https://doi.org/10.1002/mp.13544},
	year = {2019},
	month = {5},
	publisher = {Wiley},
	volume = {46},
	number = {6},
	pages = {2589--2599},
	author = {Chen, Baiyu and Kobler, Erich and Muckley, Matthew J. and Sodickson, Aaron D. and O{\textquotesingle}Donnell, Thomas and Flohr, Thomas and Schmidt, Bernhard and Sodickson, Daniel K. and Otazo, Ricardo},
	title = {{SparseCT}: System Concept and Design of Multislit Collimators},
	journal = {Medical Physics}
}

@article{thibault_statistical_2007,
	doi = {10.1118/1.2789499},
	url = {https://doi.org/10.1118%2F1.2789499},
	year = {2007},
	month = {10},
	publisher = {Wiley},
	volume = {34},
	number = {11},
	pages = {4526--4544},
	author = {Thibault, Jean-Baptiste and Sauer, Ken D. and Bouman, Charles A. and Hsieh, Jiang},
	title = {A Three-Dimensional Statistical Approach to Improved Image Quality for Multislice Helical {CT}},
	journal = {Medical Physics}
}

@article{hsieh_adaptive_1998,
	doi = {10.1118/1.598410},
	url = {https://doi.org/10.1118%2F1.598410},
	year = {1998},
	month = {10},
	publisher = {Wiley},
	volume = {25},
	number = {11},
	pages = {2139--2147},
	author = {Hsieh, Jiang},
	title = {Adaptive Streak Artifact Reduction in Computed Tomography Resulting from Excessive X-Ray Photon Noise},
	journal = {Medical Physics}
}

@article{kachelrie_adaptive_2001,
	doi = {10.1118/1.1358303},
	url = {https://doi.org/10.1118%2F1.1358303},
	year = 2001,
	month = {4},
	publisher = {Wiley},
	volume = {28},
	number = {4},
	pages = {475--490},
	author = {Kachelrie{\ss}, Marc and Watzke, Oliver and Kalender, Willi A.},
	title = {Generalized Multi-Dimensional Adaptive Filtering for Conventional and Spiral Single-Slice, Multi-Slice, and Cone-Beam {CT}},
	journal = {Medical Physics}
}

@article{forthmann_maximum_2007,
	doi = {10.1088/0031-9155/52/15/010},
	url = {https://doi.org/10.1088/0031-9155/52/15/010},
	year = 2007,
	month = {jul},
	publisher = {{IOP} Publishing},
	volume = {52},
	number = {15},
	pages = {4513--4523},
	author = {Forthmann, P. and Köhler, T. and Begemann, P. G. C. and Defrise, M.},
	title = {Penalized Maximum-Likelihood Sinogram Restoration for Dual Focal Spot Computed Tomography},
	journal = {Physics in Medicine and Biology},
}

@inproceedings{ghani_cnn_2018,
	author = {Ghani, Muhammad Usman and Karl, W. Clem},
	booktitle = {Imaging and Applied Optics},
	journal = {Imaging and Applied Optics},
	keywords = {Attenuation; Gallium nitride; Image processing; Image reconstruction; Neural networks; Noise reduction},
	pages = {MM2D.5},
	publisher = {Optical Society of America},
	title = {CNN based Sinogram Denoising for Low-Dose CT},
	year = {2018},
	url = {http://www.osapublishing.org/abstract.cfm?URI=MATH-2018-MM2D.5},
	doi = {10.1364/MATH.2018.MM2D.5},
	abstract = {Reduction of source flux results in an increase of noise in data sinograms, which subsequently produces artifacts in the corresponded reconstructed images. We use deep-learning to denoise the original sinograms, resulting in higher quality images.},
}

@article{karimi_denoising_2016,
	title = {A Denoising Algorithm for Projection Measurements in Cone-Beam Computed Tomography},
	journal = {Computers in Biology and Medicine},
	volume = {69},
	pages = {71-82},
	year = {2016},
	issn = {0010-4825},
	doi = {10.1016/j.compbiomed.2015.12.007},
	url = {https://www.sciencedirect.com/science/article/pii/S0010482515003923},
	author = {Karimi, Davood and Ward, Rabab},
	keywords = {Low-dose computed tomography, Sinogram denoising, Sparsity-based denoising, Cone-beam, Bregman method, Total variation denoising},
}

@INPROCEEDINGS{jiao_multiscale_2008,
	author = {Jiao, Chun and Wang, Dongming and Lu, Hongbing and Zhang, Zhu and Liang, Jerome Z.},
	booktitle = {IEEE Nuclear Science Symposium Conference Record}, 
	title = {Multiscale Noise Reduction on Low-Dose CT Sinogram by Stationary Wavelet Transform}, 
	year = {2008},
	volume = {},
	number = {},
	pages = {5339-5344},
	doi = {10.1109/NSSMIC.2008.4774439}
}

@article{chen_low_2017,
	doi = {10.1364/boe.8.000679},
	url = {https://doi.org/10.1364%2Fboe.8.000679},
	year = 2017,
	month = jan,
	publisher = {The Optical Society},
	volume = {8},
	number = {2},
	pages = {679},
	author = {Chen, Hu and Zhang, Yi and Zhang, Weihua and Liao, Peixi and Li, Ke and Zhou, Jiliu and Wang, Ge},
	title = {{Low}-dose {CT} via Convolutional Neural Network},
	journal = {Biomedical Optics Express}
}

@article{chen_thoracic_2012,
	doi = {10.1088/0031-9155/57/9/2667},
	url = {https://doi.org/10.1088%2F0031-9155%2F57%2F9%2F2667},
	year = 2012,
	month = apr,
	publisher = {{IOP} Publishing},
	volume = {57},
	number = {9},
	pages = {2667--2688},
	author = {Chen, Yang and Yang, Zhou and Hu, Yining and Yang, Guanyu and Zhu Yongcheng and Li, Yinsheng and Luo, Limin and Chen, Wufan and Toumoulin, Christine},
	title = {Thoracic Low-Dose {CT} Image Processing using an Artifact Suppressed Large-Scale Nonlocal Means},
	journal = {Physics in Medicine and Biology}
}

@article{ma_low_2011,
	doi = {10.1118/1.3638125},
	url = {https://doi.org/10.1118%2F1.3638125},
	year = 2011,
	month = sep,
	publisher = {Wiley},
	volume = {38},
	number = {10},
	pages = {5713--5731},
	author = {Ma, Jianhua and Huang, Jing and Feng, Qianjin and Zhang, Hua and Lu, Hongbing and Liang, Zhengrong and Chen, Wufan},
	title = {Low-Dose Computed Tomography Image Restoration using Previous Normal-Dose Scan},
	journal = {Medical Physics}
}

@article{li_adaptive_2013,
	doi = {10.1118/1.4851635},
	url = {https://doi.org/10.1118%2F1.4851635},
	year = 2013,
	month = dec,
	publisher = {Wiley},
	volume = {41},
	number = {1},
	pages = {011908},
	author = {Li, Zhoubo and Yu, Lifeng and Trzasko, Joshua D. and Lake, David S. and Blezek, Daniel J. and Fletcher, Joel G. and McCollough, Cynthia H. and Manduca Armando},
	title = {Adaptive Nonlocal Means Filtering based on Local Noise Level for {CT} Denoising},
	journal = {Medical Physics}
}

@inproceedings{kang_image_2013,
	doi = {10.1117/12.2006907},
	url = {https://doi.org/10.1117%2F12.2006907},
	year = 2013,
	month = mar,
	publisher = {{SPIE}},
	author = {Kang, Dongwoo and Slomka, Piotr and Nakazato, Ryo and Woo, Jonghye and Berman, Daniel S. and Jay Kuo, C.-C. and Dey, Damini},
	editor = {Sebastien Ourselin and David R. Haynor},
	title = {Image Denoising of Low-Radiation Dose Coronary {CT} Angiography by an Adaptive Block-matching 3D Algorithm},
	booktitle = {Medical Imaging 2013: Image Processing}
}

@article{zhu_image_2018,
	doi = {10.1038/nature25988},
	url = {https://doi.org/10.1038%2Fnature25988},
	year = 2018,
	month = mar,
	publisher = {Springer Science and Business Media {LLC}},
	volume = {555},
	number = {7697},
	pages = {487--492},
	author = {Zhu, Bo and Liu, Jeremiah Z. and Cauley, Stephen F. and Rosen, Bruce R. and Rosen Matthew S.},
	title = {Image Reconstruction by Domain-Transform Manifold Learning},
	journal = {Nature}
}

@article{tikhonov_solution_1963,
	AUTHOR = {Tikhonov, A. N.},
	TITLE = {On the solution of ill-posed problems and the method of regularization},
	JOURNAL = {Doklady Akademii Nauk SSSR},
	FJOURNAL = {Doklady Akademii Nauk SSSR},
	VOLUME = {151},
	YEAR = {1963},
	PAGES = {501--504},
	ISSN = {0002-3264},
	MRCLASS = {65.75},
	MRNUMBER = {0162377},
	MRREVIEWER = {P. Henrici},
}

@article{sidky_accurate_2006,
	author = {Sidky, Emil Y. and Kao, Chien-Min and Pan, Xiaochuan},
	journal = {Journal of X-Ray Science and Technology},
	year = {2006},
	pages = {119--139},
	volume = {14},
	title = {Accurate Image Reconstruction from Few-Views and Limited-Angle Data in Divergent-Beam CT},
}

@article{sidky_reconstruction_2008,
	doi = {10.1088/0031-9155/53/17/021},
	url = {https://doi.org/10.1088%2F0031-9155%2F53%2F17%2F021},
	year = {2008},
	month = aug,
	publisher = {{IOP} Publishing},
	volume = {53},
	number = {17},
	pages = {4777--4807},
	author = {Sidky, Emil Y. and Pan, Xiaochuan},
	title = {Image Reconstruction in Circular Cone-Beam Computed Tomography by Constrained, Total-Variation Minimization},
	journal = {Physics in Medicine and Biology}
}

@article{niu_sparse_2014,
	doi = {10.1088/0031-9155/59/12/2997},
	url = {https://doi.org/10.1088%2F0031-9155%2F59%2F12%2F2997},
	year = {2014},
	month = {may},
	publisher = {{IOP} Publishing},
	volume = {59},
	number = {12},
	pages = {2997--3017},
	author = {Niu, Shanzhou and Gao, Yang and Bian, Zhaoying and Huang, Jing and Chen, Wufan and Yu, Gaohang and Liang, Zhengrong and Ma, Jianhua},
	title = {Sparse-View X-Ray {CT} Reconstruction via Total Generalized Variation Regularization},
	journal = {Physics in Medicine and Biology}
}

@article{tang_performance_2009,
	doi = {10.1088/0031-9155/54/19/008},
	url = {https://doi.org/10.1088%2F0031-9155%2F54%2F19%2F008},
	year = 2009,
	month = sep,
	publisher = {{IOP} Publishing},
	volume = {54},
	number = {19},
	pages = {5781--5804},
	author = {Tang, Jie and Nett, Brian E. and Chen, Guang-Hong},
	title = {Performance Comparison between Total Variation ({TV})-Based Compressed Sensing and Statistical Iterative Reconstruction Algorithms},
	journal = {Physics in Medicine and Biology}
}

@article{tian_reconstruction_2011,
	doi = {10.1088/0031-9155/56/18/011},
	url = {https://doi.org/10.1088%2F0031-9155%2F56%2F18%2F011},
	year = 2011,
	month = aug,
	publisher = {{IOP} Publishing},
	volume = {56},
	number = {18},
	pages = {5949--5967},
	author = {Tian, Zhen and Jia, Xun and Yuan, Kehong and Pan, Tinsu and Jiang, Steve B.},
	title = {Low-Dose {CT} Reconstruction via Edge-Preserving Total Variation Regularization},
	journal = {Physics in Medicine and Biology}
}

@article{yang_high_2010,
	doi = {10.1088/0266-5611/26/3/035013},
	url = {https://doi.org/10.1088%2F0266-5611%2F26%2F3%2F035013},
	year = 2010,
	month = feb,
	publisher = {{IOP} Publishing},
	volume = {26},
	number = {3},
	pages = {035013},
	author = {Yang, Jiansheng and Yu, Hengyong and Jiang, Ming and Wang, Ge},
	title = {High-Order Total Variation Minimization for Interior Tomography},
	journal = {Inverse Problems}
}

@article{zhang_few-view_2013,
	doi = {10.1002/ima.22058},
	url = {https://doi.org/10.1002%2Fima.22058},
	year = 2013,
	month = aug,
	publisher = {Wiley},
	volume = {23},
	number = {3},
	pages = {249--255},
	author = {Zhang, Yi and Zhang, Wei-Hua and Chen, Hu and Yang, Meng-Long and Li, Tai-Yong and Zhou, Ji-Liu},
	title = {Few-View Image Reconstruction combining Total Variation and a High-Order Norm},
	journal = {International Journal of Imaging Systems and Technology}
}

@article{liu_total_2014,
	doi = {10.1109/tmi.2013.2295738},
	url = {https://doi.org/10.1109%2Ftmi.2013.2295738},
	year = 2014,
	month = mar,
	publisher = {Institute of Electrical and Electronics Engineers},
	volume = {33},
	number = {3},
	pages = {749--763},
	author = {Liu, Yan and Liang, Zhengrong and Ma, Jianhua and Lu, Hongbing and Wang, Ke and Zhang, Hao and Moore, William},
	title = {Total Variation-Stokes Strategy for Sparse-View X-Ray {CT} Image Reconstruction},
	journal = {{IEEE} Transactions on Medical Imaging}
}

@article{bredies_total_2010,
	doi = {10.1137/090769521},
	url = {https://doi.org/10.1137%2F090769521},
	year = 2010,
	month = jan,
	publisher = {Society for Industrial {\&} Applied Mathematics ({SIAM})},
	volume = {3},
	number = {3},
	pages = {492--526},
	author = {Bredies, Kristian and Kunisch, Karl and Pock, Thomas},
	title = {Total Generalized Variation},
	journal = {{SIAM} Journal on Imaging Sciences}
}

@article{zhu_filters_1998,
	doi = {10.1023/a:1007925832420},
	url = {https://doi.org/10.1023%2Fa%3A1007925832420},
	year = 1998,
	publisher = {Springer Science and Business Media {LLC}},
	volume = {27},
	number = {2},
	pages = {107--126},
	author = {Zhu, Song Chun and Wu, Yingnian and Mumford, David},
	journal = {International Journal of Computer Vision},
	title = {Filters, Random Fields and Maximum Entropy (FRAME): Towards a Unified Theory for Texture Modeling},
}

@INPROCEEDINGS{roth_fields_2005,
	author = {Roth, S. and Black, M. J.},
	booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
	title = {Fields of Experts: A Framework for Learning Image Priors},
	year = {2005},
	volume = {2},
	number = {},
	pages = {860-867 vol. 2},
	doi = {10.1109/CVPR.2005.160}
}

@article{kunisch_bilevel_2013,
	doi = {10.1137/120882706},
	url = {https://doi.org/10.1137%2F120882706},
	year = 2013,
	month = jan,
	publisher = {Society for Industrial {\&} Applied Mathematics ({SIAM})},
	volume = {6},
	number = {2},
	pages = {938--983},
	author = {Kunisch, Karl and Pock, Thomas},
	title = {A Bilevel Optimization Approach for Parameter Learning in Variational Models},
	journal = {{SIAM} Journal on Imaging Sciences}
}

@InProceedings{domke_generic_2012,
	title = {Generic Methods for Optimization-Based Modeling},
	author = {Domke, Justin},
	booktitle = {Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics}, pages = {318--326},
	year = {2012},
	editor = {Neil D. Lawrence and Mark Girolami},
	volume = {22},
	series = {Proceedings of Machine Learning Research},
	address = {La Palma, Canary Islands},
	month = {4},
	publisher = {PMLR},
	pdf = {http://proceedings.mlr.press/v22/domke12/domke12.pdf},
	url = {http://proceedings.mlr.press/v22/domke12.html},
	abstract = {"Energy” models for continuous domains can be applied to many problems, but often suffer from high computational expense in training, due to the need to repeatedly minimize the energy function to high accuracy. This paper considers a modified setting, where the model is trained in terms of results after optimization is truncated to a fixed number of iterations. We derive “backpropagating” versions of gradient descent, heavy-ball and LBFGS. These are simple to use, as they require as input only routines to compute the gradient of the energy with respect to the domain and parameters. Experimental results on denoising and image labeling problems show that learning with truncated optimization greatly reduces computational expense compared to “full” fitting.}
}

@article{barbu_training_2009,
	title = {Training an Active Random Field for Real-Time Image Denoising},
	volume = {18},
	issn = {1057-7149, 1941-0042},
	abstract = {Many computer vision problems can be formulated in a Bayesian framework based on Markov Random Fields ({MRF}) or Conditional Random Fields ({CRF}). Generally, the {MRF}/{CRF} model is learned independently of the inference algorithm that is used to obtain the ﬁnal result. In this paper, we observe considerable gains in speed and accuracy by training the {MRF}/{CRF} model together with a fast and suboptimal inference algorithm. An Active Random Field ({ARF}) is deﬁned as a combination of a {MRF}/{CRF} based model and a fast inference algorithm for the {MRF}/{CRF} model. This combination is trained through an optimization of a loss function and a training set consisting of pairs of input images and desired outputs. We apply the Active Random Field concept to image denoising, using the Fields of Experts {MRF} together with a 1-4 iteration gradient descent algorithm for inference. Experimental validation on unseen data shows that the Active Random Field approach obtains an improved benchmark performance as well as a 10003000 times speedup compared to the Fields of Experts {MRF}. Using the {ARF} approach, image denoising can be performed in real-time, at 8fps on a single {CPU} for a 256×256 image sequence, with close to state-of-the-art accuracy.},
	pages = {2451--2462},
	number = {11},
	journaltitle = {{IEEE} Transactions on Image Processing},
	shortjournal = {{IEEE} Trans. on Image Process.},
	author = {Barbu, A.},
	journal = {IEEE Transactions on Image Processing}, 
	date = {2009-11},
	year = {2009},
	langid = {english},
	file = {Barbu - 2009 - Training an Active Random Field for Real-Time Imag.pdf:/home/martin/Zotero/storage/CDXYPWEX/Barbu - 2009 - Training an Active Random Field for Real-Time Imag.pdf:application/pdf},
	doi = {10.1109/TIP.2009.2028254}
}

@INPROCEEDINGS{samuel_learning_2009,
	author = {Samuel, Kegan G. G. and Tappen, Marshall F.},
	booktitle = {IEEE Conference on Computer Vision and Pattern Recognition}, 
	title = {Learning Optimized MAP Estimates in Continuously-Valued MRF Models}, 
	year = {2009},
	volume = {},
	number = {},
	pages = {477-484},
	doi = {10.1109/CVPR.2009.5206774}}

 @InProceedings{mehmood_automatic_2020,
	title = {Automatic Differentiation of Some First-Order Methods in Parametric Optimization},
	author = {Mehmood, Sheheryar and Ochs, Peter},
	booktitle = {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
	pages = {1584--1594},
	year = {2020},
	editor = {Silvia Chiappa and Roberto Calandra},
	volume = {108},
	series = {Proceedings of Machine Learning Research},
	month = {8},
	publisher = {PMLR},
	pdf = {http://proceedings.mlr.press/v108/mehmood20a/mehmood20a.pdf},
	url = { http://proceedings.mlr.press/v108/mehmood20a.html },
	abstract = {We aim at computing the derivative of the solution to a parametric optimization problem with respect to the involved parameters. For a class broader than that of strongly convex functions, this can be achieved by automatic differentiation of iterative minimization algorithms. If the iterative algorithm converges pointwise, then we prove that the derivative sequence also converges pointwise to the derivative of the minimizer with respect to the parameters. Moreover, we provide convergence rates for both sequences. In particular, we prove that the accelerated convergence rate of the Heavy-ball method compared to Gradient Descent also accelerates the derivative computation. An experiment with L2-Regularized Logistic Regression validates the theoretical results.}
}

@ARTICLE{chen_learn_2018,
	author = {Chen, Hu and Zhang, Yi and Chen, Yunjin and Zhang, Junfeng and Zhang, Weihua and Sun, Huaiqiang and Lv, Yang and Liao, Peixi and Zhou, Jiliu and Wang, Ge},
	journal = {IEEE Transactions on Medical Imaging},
	title = {LEARN: Learned Experts’ Assessment-Based Reconstruction Network for Sparse-Data CT}, 
	year = {2018},
	volume = {37},
	number = {6},
	pages = {1333-1347},
	doi = {10.1109/TMI.2018.2805692}
}

@book{bishop_pattern_2006,
	author = {Bishop, Christopher M.},
	title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
	year = {2006},
	isbn = {0387310738},
	publisher = {Springer-Verlag},
	address = {Berlin, Heidelberg}
}

@book{brooks_handbook_2011,
	author = {Brooks, Steve and Gelman, Andrew and Galin, Jones and Menng, Xiao-Li},
	title = {Handbook of Markov Chain Monte Carlo},
	year = {2011},
	publisher = {Chapman and Hall/CRC},
	isbn = {9781420079418},
}

@ARTICLE{geman_stochastic_1984,
	author={Geman, Stuart and Geman, Donald},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	title={Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images}, 
	year={1984},
	volume={PAMI-6},
	number={6},
	pages={721-741},
	doi={11.1109/TPAMI.1984.4767596}
}

@article{hastings_monte_1970,
	doi = {10.1093/biomet/57.1.97},
	url = {https://doi.org/10.1093%2Fbiomet%2F57.1.97},
	year = {1970},
	month = {4},
	publisher = {Oxford University Press ({OUP})},
	volume = {57},
	number = {1},
	pages = {97--109},
	author = {Hastings, W. K.},
	title = {Monte Carlo Sampling Methods using Markov Chains and Their Applications},
	journal = {Biometrika}
}

@article{douane_hybrid_1987,
	title = {Hybrid Monte Carlo},
	journal = {Physics Letters B},
	volume = {195},
	number = {2},
	pages = {216-222},
	year = {1987},
	issn = {0370-2693},
	doi = {10.1016/0370-2693(87)91197-X},
	url = {https://www.sciencedirect.com/science/article/pii/037026938791197X},
	author = {Duane, Simon and Kennedy, A.D. and Pendleton, Brian J. and Roweth, Duncan},
	abstract = {We present a new method for the numerical simulation of lattice field theory. A hybrid (molecular dynamics/Langevin) algorithm is used to guide a Monte Carlo simulation. There are no discretization errors even for large step sizes. The method is especially efficient for systems such as quantum chromodynamics which contain fermionic degrees of freedom. Detailed results are presented for four-dimensional compact quantum electrodynamics including the dynamical effects of electrons.}
}

@article{roberts_optimal_1998,
	doi = {10.1111/1467-9868.00123},
	url = {https://doi.org/10.1111%2F1467-9868.00123},
	year = {1998},
	month = {2},
	publisher = {Wiley},
	volume = {60},
	number = {1},
	pages = {255--268},
	author = {Roberts, Gareth O. and Rosenthal, Jeffrey S.},
	title = {Optimal scaling of discrete approximations to Langevin diffusions},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)}
}

@book{murphy_machine_2012,
	author = {Murphy, Kevin P.},
	title = {Machine Learning: A Probabilistic Perspective},
	year = {2012},
	publisher = {MIT Press},
	isbn = {9780262018029},
}

@article{hinton_training_2002,
	doi = {10.1162/089976602760128018},
	url = {https://doi.org/10.1162%2F089976602760128018},
	year = 2002,
	month = {8},
	publisher = {{MIT} Press - Journals},
	volume = {14},
	number = {8},
	pages = {1771--1800},
	author = {Geoffrey E. Hinton},
	title = {Training Products of Experts by Minimizing Contrastive Divergence},
	journal = {Neural Computation}
}

@inproceedings{nijkamp_shortrun_2019,
	author = {Nijkamp, Erik and Hill, Mitch and Zhu, Song-Chun and Wu, Ying Nian},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {Learning Non-Convergent Non-Persistent Short-Run MCMC Toward Energy-Based Model},
	url = {https://proceedings.neurips.cc/paper/2019/file/2bc8ae25856bc2a6a1333d1331a3b7a6-Paper.pdf},
	volume = {32},
	year = {2019}
}

@article{nijkamp_anatomy_2019,
	title={On the Anatomy of MCMC-Based Maximum Likelihood Learning of Energy-Based Models},
	volume={34},
	url={https://ojs.aaai.org/index.php/AAAI/article/view/5973},
	DOI={10.1609/aaai.v34i04.5973},
	abstractNote={&lt;p&gt;This study investigates the effects of Markov chain Monte Carlo (MCMC) sampling in unsupervised Maximum Likelihood (ML) learning. Our attention is restricted to the family of unnormalized probability densities for which the negative log density (or energy function) is a ConvNet. We find that many of the techniques used to stabilize training in previous studies are not necessary. ML learning with a ConvNet potential requires only a few hyper-parameters and no regularization. Using this minimal framework, we identify a variety of ML learning outcomes that depend solely on the implementation of MCMC sampling.&lt;/p&gt;&lt;p&gt;On one hand, we show that it is easy to train an energy-based model which can sample realistic images with short-run Langevin. ML can be effective and stable even when MCMC samples have much higher energy than true steady-state samples throughout training. Based on this insight, we introduce an ML method with purely noise-initialized MCMC, high-quality short-run synthesis, and the same budget as ML with informative MCMC initialization such as CD or PCD. Unlike previous models, our energy model can obtain realistic high-diversity samples from a noise signal after training.&lt;/p&gt;&lt;p&gt;On the other hand, ConvNet potentials learned with non-convergent MCMC do not have a valid steady-state and cannot be considered approximate unnormalized densities of the training data because long-run MCMC samples differ greatly from observed images. We show that it is much harder to train a ConvNet potential to learn a steady-state over realistic images. To our knowledge, long-run MCMC samples of all previous models lose the realism of short-run samples. With correct tuning of Langevin noise, we train the first ConvNet potentials for which long-run and steady-state MCMC samples are realistic images.&lt;/p&gt;},
	number={04},
	journal={Proceedings of the AAAI Conference on Artificial Intelligence},
	author={Nijkamp, Erik and Hill, Mitch and Han, Tian and Zhu, Song-Chun and Wu, Ying Nian},
	year={2020},
	month={Apr.},
	pages={5272-5280}
}

@inproceedings{du_implicit_2019,
	author = {Du, Yilun and Mordatch, Igor},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {Implicit Generation and Modeling with Energy Based Models},
	url = {https://proceedings.neurips.cc/paper/2019/file/378a063b8fdb1db941e34f4bde584c7d-Paper.pdf},
	volume = {32},
	year = {2019}
}

@article{du_improved_2020,
	author    = {Du, Yilun and Li, Shuang and Tenenbaum, Joshua B. and Mordatch, Igor},
	title     = {Improved Contrastive Divergence Training of Energy Based Models},
	journal   = {CoRR},
	volume    = {abs/2012.01316},
	year      = {2020},
	url       = {https://arxiv.org/abs/2012.01316},
	archivePrefix = {arXiv},
	eprint    = {2012.01316},
	timestamp = {Fri, 04 Dec 2020 12:07:23 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2012-01316.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{goodfellow_generative_2014,
	author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	title = {Generative Adversarial Nets},
	year = {2014},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
	abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to ½ everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
	booktitle = {Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2},
	pages = {2672–2680},
	numpages = {9},
	location = {Montreal, Canada},
	series = {NIPS'14}
}

@InProceedings{perpinan_contrastive_2005,
	title = {On Contrastive Divergence Learning},
	author = {Carreira-Perpi{\~n}\'an, Miguel \'A. and Hinton, Geoffrey},
	booktitle = {Proceedings of the Tenth International Workshop on Artificial Intelligence and Statistics},
	pages = {33--40},
	year = {2005},
	editor = {Cowell, Robert G. and Ghahramani, Zoubin},
	volume = {R5},
	series = {Proceedings of Machine Learning Research},
	month = {06--08 Jan},
	publisher = {PMLR},
	pdf = {http://proceedings.mlr.press/r5/carreira-perpinan05a/carreira-perpinan05a.pdf},
	url = {http://proceedings.mlr.press/r5/carreira-perpinan05a.html},
}

@article{grenader_representations_1994,
	ISSN = {00359246},
	URL = {http://www.jstor.org/stable/2346184},
	abstract = {Modern sensor technologies, especially in biomedicine, produce increasingly detailed and informative image ensembles, many extremely complex. It will be argued that pattern theory can supply mathematical representations of subject-matter knowledge that can be used as a basis for algorithmic `understanding' of such pictures. After a brief survey of the basic principles of pattern theory we shall illustrate them by an application to a concrete situation: high magnification (greater than 15 000 ×) electron micrographs of cardiac muscle cells. The aim is to build algorithms for automatic hypothesis formation concerning the number, location, orientation and shape of mitochondria and membranes. For this we construct a pattern theoretic model in the form of a prior probability measure on the space of configurations describing these hypotheses. This measure is synthesized by solving sequentially a jump-diffusion equation of generalized Langevin form. The jumps occur for the creation-annihilation of hypotheses, corresponding to a jump from one continuum to another in configuration (hypothesis) space. These continua (subhypotheses) are expressed in terms of products of low dimensional Lie groups acting on the generators of a template. We use a modified Bayes approach to obtain the hypothesis formation, also organized by solving a generalized Langevin equation. To justify this it is shown that the resulting jump-diffusion process is ergodic so that the solution converges to the desired probability measure. To speed up the convergence we reduce the computation of the drift term in the stochastic differential equation analytically to a curvilinear integral, with the random term computed almost instantaneously. The algorithms thus obtained are implemented, both for mitochondria and membranes, on a 4000 processor parallel machine. Photographs of the graphics illustrate how automatic hypothesis formation is achieved. This approach is applied to deformable neuroanatomical atlases and tracking recognition from narrow band and high resolution sensor arrays.},
	author = {Grenander, Ulf and Miller, Michael I.},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	number = {4},
	pages = {549--603},
	publisher = {[Royal Statistical Society, Wiley]},
	title = {Representations of Knowledge in Complex Systems},
	volume = {56},
	year = {1994}
}

@article{rossky_brownian_1978,
	author = {Rossky, P. J.  and Doll, J. D.  and Friedman, H. L. },
	title = {Brownian dynamics as smart Monte Carlo Simulation},
	journal = {The Journal of Chemical Physics},
	volume = {69},
	number = {10},
	pages = {4628-4633},
	year = {1978},
	doi = {10.1063/1.436415},
	URL = {https://doi.org/10.1063/1.436415},
	eprint = {https://doi.org/10.1063/1.436415}
}

@article{roberts_exponential_1996,
	author = {Roberts, Gareth O. and Tweedie, Richard L.},
	title = {Exponential Convergence of Langevin Distributions and their Discrete Approximations},
	volume = {2},
	journal = {Bernoulli},
	number = {4},
	publisher = {Bernoulli Society for Mathematical Statistics and Probability},
	pages = {341 -- 363},
	keywords = {Diffusions, discrete approximations, geometric ergodicity, Hastings algorithms, irreducible Markov processes, Langevin models, Markov chain Monte Carlo, Metropolis algorithms, posterior distributions},
	year = {1996},
	doi = {bj/1178291835},
	URL = {https://doi.org/}
}

@inproceedings{zhang_convolutional_2019,
	title={Making Convolutional Networks Shift-Invariant Again},
	author={Zhang, Richard},
	booktitle={International Conference on Machine Learning},
	year={2019},
}

@article{ramachandran_searching_2017,
	author    = {Prajit Ramachandran and
		       Barret Zoph and
		       Quoc V. Le},
	title     = {Searching for Activation Functions},
	journal   = {CoRR},
	volume    = {abs/1710.05941},
	year      = {2017},
	url       = {http://arxiv.org/abs/1710.05941},
	archivePrefix = {arXiv},
	eprint    = {1710.05941},
	timestamp = {Mon, 13 Aug 2018 16:48:44 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1710-05941.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{moen_lowdose_2020,
	author = {Moen, Taylor R. and Chen, Baiyu and Holmes III, David R. and Duan, Xinhui and Yu, Zhicong and Yu, Lifeng and Leng, Shuai and Fletcher, Joel G. and McCollough, Cynthia H.},
	title = {Low-dose CT image and projection dataset},
	journal = {Medical Physics},
	volume = {48},
	number = {2},
	pages = {902-911},
	keywords = {CT projection data, iterative reconstruction, low-dose CT, machine learning, patient data},
	doi = {10.1002/mp.14594},
	url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.14594},
	eprint = {https://aapm.onlinelibrary.wiley.com/doi/pdf/10.1002/mp.14594},
	abstract = {Purpose To describe a large, publicly available dataset comprising computed tomography (CT) projection data from patient exams, both at routine clinical doses and simulated lower doses. Acquisition and Validation Methods The library was developed under local ethics committee approval. Projection and image data from 299 clinically performed patient CT exams were archived for three types of clinical exams: noncontrast head CT scans acquired for acute cognitive or motor deficit, low-dose noncontrast chest scans acquired to screen high-risk patients for pulmonary nodules, and contrast-enhanced CT scans of the abdomen acquired to look for metastatic liver lesions. Scans were performed on CT systems from two different CT manufacturers using routine clinical protocols. Projection data were validated by reconstructing the data using several different reconstruction algorithms and through use of the data in the 2016 Low Dose CT Grand Challenge. Reduced dose projection data were simulated for each scan using a validated noise-insertion method. Radiologists marked location and diagnosis for detected pathologies. Reference truth was obtained from the patient medical record, either from histology or subsequent imaging. Data Format and Usage Notes Projection datasets were converted into the previously developed DICOM-CT-PD format, which is an extended DICOM format created to store CT projections and acquisition geometry in a nonproprietary format. Image data are stored in the standard DICOM image format and clinical data in a spreadsheet. Materials are provided to help investigators use the DICOM-CT-PD files, including a dictionary file, data reader, and user manual. The library is publicly available from The Cancer Imaging Archive (https://doi.org/10.7937/9npb-2637). Potential Applications This CT data library will facilitate the development and validation of new CT reconstruction and/or denoising algorithms, including those associated with machine learning or artificial intelligence. The provided clinical information allows evaluation of task-based diagnostic performance.},
	year = {2021}
}

@inproceedings{tieleman_persistent_2008,
	author = {Tieleman, Tijmen},
	title = {Training Restricted Boltzmann Machines Using Approximations to the Likelihood Gradient},
	year = {2008},
	isbn = {9781605582054},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1390156.1390290},
	doi = {10.1145/1390156.1390290},
	abstract = {A new algorithm for training Restricted Boltzmann Machines is introduced. The algorithm, named Persistent Contrastive Divergence, is different from the standard Contrastive Divergence algorithms in that it aims to draw samples from almost exactly the model distribution. It is compared to some standard Contrastive Divergence and Pseudo-Likelihood algorithms on the tasks of modeling and classifying various types of data. The Persistent Contrastive Divergence algorithm outperforms the other algorithms, and is equally fast and simple.},
	booktitle = {Proceedings of the 25th International Conference on Machine Learning},
	pages = {1064–1071},
	numpages = {8},
	location = {Helsinki, Finland},
	series = {ICML '08}
}

@inproceedings{kingma_adam_2015,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{kobler_total_2020,
	title     = {Total Deep Variation for Linear Inverse Problems},
	author    = {Kobler, Erich and Effland, Alexander and Kunisch, Karl and Pock, Thomas},
	booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
	year      = {2020}
}

@article{chambolle_primal_2010,
	doi = {10.1007/s10851-010-0251-1},
	url = {https://doi.org/10.1007%2Fs10851-010-0251-1},
	year = 2010,
	month = dec,
	publisher = {Springer Science and Business Media {LLC}},
	volume = {40},
	number = {1},
	pages = {120--145},
	author = {Antonin Chambolle and Thomas Pock},
	title = {A First-Order Primal-Dual Algorithm for Convex Problems with~Applications to Imaging},
	journal = {Journal of Mathematical Imaging and Vision}
}

@article{vanaarle_astra_2016,
	doi = {10.1364/oe.24.025129},
	url = {https://doi.org/10.1364%2Foe.24.025129},
	year = 2016,
	month = oct,
	publisher = {The Optical Society},
	volume = {24},
	number = {22},
	pages = {25129},
	author = {Wim van Aarle and Willem Jan Palenstijn and Jeroen Cant and Eline Janssens and Folkert Bleichrodt and Andrei Dabravolski and Jan De Beenhouwer and K. Joost Batenburg and Jan Sijbers},
	title = {Fast and flexible X-ray tomography using the {ASTRA} toolbox},
	journal = {Optics Express}
}

@article{vanaarle_astra_2015,
	doi = {10.1016/j.ultramic.2015.05.002},
	url = {https://doi.org/10.1016%2Fj.ultramic.2015.05.002},
	year = 2015,
	month = oct,
	publisher = {Elsevier {BV}},
	volume = {157},
	pages = {35--47},
	author = {Wim van Aarle and Willem Jan Palenstijn and Jan De Beenhouwer and Thomas Altantzis and Sara Bals and K. Joost Batenburg and Jan Sijbers},
	title = {The {ASTRA} Toolbox: A platform for advanced algorithm development in electron tomography},
	journal = {Ultramicroscopy}
}

@book{goodfellow_deeplearning_2016,
    title={Deep Learning},
    author={Goodfellow, Ian J. and Bengio, Yoshua and Courville, Aaron},
    publisher={MIT Press},
    year={2016}
}

@inproceedings{krizhevsky_imagenet_2017,
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {ImageNet Classification with Deep Convolutional Neural Networks},
	url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
	volume = {25},
	year = {2012}
}

@article{chen_deeplab_2018,
	author={Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L.},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	title={DeepLab Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs}, 
	year={2018},
	volume={40},
	number={4},
	pages={834-848},
	doi={10.1109/TPAMI.2017.2699184}
}

@article{kamnitsas_efficient_2017,
	title = {Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation},
	journal = {Medical Image Analysis},
	volume = {36},
	pages = {61-78},
	year = {2017},
	issn = {1361-8415},
	doi = {10.1016/j.media.2016.10.004},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841516301839},
	author = {Konstantinos Kamnitsas and Christian Ledig and Virginia F.J. Newcombe and Joanna P. Simpson and Andrew D. Kane and David K. Menon and Daniel Rueckert and Ben Glocker},
	keywords = {3D convolutional neural network, Fully connected CRF, Segmentation, Brain lesions, Deep learning}
}

@article{liu_detecting_2017,
  author    = {Yun Liu and
               Krishna Gadepalli and
               Mohammad Norouzi and
               George E. Dahl and
               Timo Kohlberger and
               Aleksey Boyko and
               Subhashini Venugopalan and
               Aleksei Timofeev and
               Philip Q. Nelson and
               Gregory S. Corrado and
               Jason D. Hipp and
               Lily Peng and
               Martin C. Stumpe},
  title     = {Detecting Cancer Metastases on Gigapixel Pathology Images},
  journal   = {CoRR},
  volume    = {abs/1703.02442},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.02442},
  archivePrefix = {arXiv},
  eprint    = {1703.02442},
  timestamp = {Sat, 23 Jan 2021 01:19:53 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/LiuGNDKBVTNCHPS17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{zhang_beyond_2017,
	title={Beyond a {Gaussian} denoiser: Residual learning of deep {CNN} for image denoising},
	author={Zhang, Kai and Zuo, Wangmeng and Chen, Yunjin and Meng, Deyu and Zhang, Lei},
	journal={IEEE Transactions on Image Processing},
	year={2017},
	volume={26},
	number={7},
	pages={3142-3155},
}

@InProceedings{nah_deep_2017,
	author = {Nah, Seungjun and Kim, Tae Hyun and Lee, Kyoung Mu},
	title = {Deep Multi-Scale Convolutional Neural Network for Dynamic Scene Deblurring},
	booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
	month = {July},
	year = {2017}
}

@article{wang_vannier_cheng_1999,
	title={Iterative X-ray Cone-Beam Tomography for Metal Artifact Reduction and Local Region Reconstruction},
	volume={5},
	DOI={10.1017/S1431927699000057},
	number={1},
	journal={Microscopy and Microanalysis},
	publisher={Cambridge University Press},
	author={Wang, Ge and Vannier, Michael W. and Cheng, Ping-Chin},
	year={1999},
	pages={58–65},
}

@article{saad_iterative_2000,
	title = {Iterative solution of linear systems in the 20th century},
	journal = {Journal of Computational and Applied Mathematics},
	volume = {123},
	number = {1},
	pages = {1-33},
	year = {2000},
	note = {Numerical Analysis 2000. Vol. III: Linear Algebra},
	issn = {0377-0427},
	doi = {10.1016/S0377-0427(00)00412-X},
	url = {https://www.sciencedirect.com/science/article/pii/S037704270000412X},
	author = {Yousef Saad and Henk A. {van der Vorst}},
	keywords = {ADI, Krylov subspace methods, Multigrid, Polynomial acceleration, Preconditioning, Relaxation methods, SOR, Sparse approximate inverse},
	abstract = {This paper sketches the main research developments in the area of iterative methods for solving linear systems during the 20th century. Although iterative methods for solving linear systems find their origin in the early 19th century (work by Gauss), the field has seen an explosion of activity spurred by demand due to extraordinary technological advances in engineering and sciences. The past five decades have been particularly rich in new developments, ending with the availability of large toolbox of specialized algorithms for solving the very large problems which arise in scientific and industrial computational models. As in any other scientific area, research in iterative methods has been a journey characterized by a chain of contributions building on each other. It is the aim of this paper not only to sketch the most significant of these contributions during the past century, but also to relate them to one another.}
}

@article{rudin_nonlinear_1992,
	title = {Nonlinear total variation based noise removal algorithms},
	journal = {Physica D: Nonlinear Phenomena},
	volume = {60},
	number = {1},
	pages = {259-268},
	year = {1992},
	issn = {0167-2789},
	doi = {10.1016/0167-2789(92)90242-F},
	url = {https://www.sciencedirect.com/science/article/pii/016727899290242F},
	author = {Leonid I. Rudin and Stanley Osher and Emad Fatemi},
	abstract = {A constrained optimization type of numerical algorithm for removing noise from images is presented. The total variation of the image is minimized subject to constraints involving the statistics of the noise. The constraints are imposed using Lanrange multipliers. The solution is obtained using the gradient-projection method. This amounts to solving a time dependent partial differential equation on a manifold determined by the constraints. As t  the solution converges to a steady state which is the denoised image. The numerical algorithm is simple and relatively fast. The results appear to be state-of-the-art for very noisy images. The method is noninvasive, yielding sharp edges in the image. The technique could be interpreted as a first step of moving each level set of the image normal to itself with velocity equal to the curvature of the level set divided by the magnitude of the gradient of the image, and a second step which projects the image back onto the constraint set.}
}

@article{getreuer_rudin_2012,
	title   = {{Rudin-Osher-Fatemi Total Variation Denoising using Split Bregman}},
	author  = {Getreuer, Pascal},
	journal = {{Image Processing On Line}},
	volume  = {2},
	pages   = {74--95},
	year    = {2012},
	doi     = {10.5201/ipol.2012.g-tvd}
}

@article{chan_constrained_2013,
	doi = {10.1137/110860185},
	url = {https://doi.org/10.1137%2F110860185},
	year = 2013,
	month = jan,
	publisher = {Society for Industrial {\&} Applied Mathematics ({SIAM})},
	volume = {6},
	number = {1},
	pages = {680--697},
	author = {Raymond H. Chan and Min Tao and Xiaoming Yuan},
	title = {Constrained Total Variation Deblurring Models and Fast Algorithms Based on Alternating Direction Method of Multipliers},
	journal = {{SIAM} Journal on Imaging Sciences}
}

@article{chen_limited_2013,
	doi = {10.1088/0031-9155/58/7/2119},
	url = {https://doi.org/10.1088%2F0031-9155%2F58%2F7%2F2119},
	year = 2013,
	month = mar,
	publisher = {{IOP} Publishing},
	volume = {58},
	number = {7},
	pages = {2119--2141},
	author = {Zhiqiang Chen and Xin Jin and Liang Li and Ge Wang},
	title = {A limited-angle {CT} reconstruction method based on anisotropic {TV} minimization},
	journal = {Physics in Medicine and Biology}
}

@article{barrett_artifacts_2004,
	doi = {10.1148/rg.246045065},
	url = {https://doi.org/10.1148%2Frg.246045065},
	year = 2004,
	month = nov,
	publisher = {Radiological Society of North America ({RSNA})},
	volume = {24},
	number = {6},
	pages = {1679--1691},
	author = {Julia F. Barrett and Nicholas Keat},
	title = {Artifacts in {CT}: Recognition and Avoidance},
	journal = {{RadioGraphics}}
}

@InProceedings{hammernik_deep_2017,
	author="Hammernik, Kerstin and W{\"u}rfl, Tobias and Pock, Thomas and Maier, Andreas",
	editor="Maier-Hein, geb. Fritzsche, Klaus Hermann and Deserno, geb. Lehmann, Thomas Martin and Handels, Heinz and Tolxdorff, Thomas",
	title="A Deep Learning Architecture for Limited-Angle Computed Tomography Reconstruction",
	booktitle="Bildverarbeitung f{\"u}r die Medizin 2017",
	year="2017",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="92--97",
	abstract="Limited-angle computed tomography suffers from missing data in the projection domain, which results in intensity inhomogeneities and streaking artifacts in the image domain. We address both challenges by a two-step deep learning architecture: First, we learn compensation weights that account for the missing data in the projection domain and correct for intensity changes. Second, we formulate an image restoration problem as a variational network to eliminate coherent streaking artifacts. We perform our experiments on realistic data and we achieve superior results for destreaking compared to state-of-the-art non-linear filtering methods in literature. We show that our approach eliminates the need for manual tuning and enables joint optimization of both correction schemes.",
	isbn="978-3-662-54345-0"
}

@article{hammernik_learning_2017,
	doi = {10.1002/mrm.26977},
	url = {https://doi.org/10.1002%2Fmrm.26977},
	year = 2017,
	month = nov,
	publisher = {Wiley},
	volume = {79},
	number = {6},
	pages = {3055--3071},
	author = {Kerstin Hammernik and Teresa Klatzer and Erich Kobler and Michael P. Recht and Daniel K. Sodickson and Thomas Pock and Florian Knoll},
	title = {Learning a variational network for reconstruction of accelerated {MRI} data},
	journal = {Magnetic Resonance in Medicine}
}

@ARTICLE{shepp_fourier_1974,
	author={Shepp, L. A. and Logan, B. F.},
	journal={IEEE Transactions on Nuclear Science}, 
	title={The Fourier reconstruction of a head section}, 
	year={1974},
	volume={21},
	number={3},
	pages={21-43},
	doi={11.1109/TNS.1974.6499235}
}

@ARTICLE{censor_bicav_2001,
	author={Censor, Y. and Gordon, D. and Gordon, R.},
	journal={IEEE Transactions on Medical Imaging}, 
	title={BICAV: a block-iterative parallel algorithm for sparse systems with pixel-related weighting},
	year={2001},
	volume={20},
	number={10},
	pages={1050-1060},
	doi={10.1109/42.959302}
}

@INPROCEEDINGS{donghwan_accelerated_2011,
	author={Kim, Donghwan and Fessler, Jeffrey A.},
	booktitle={IEEE International Symposium on Biomedical Imaging: From Nano to Macro}, 
	title={Accelerated ordered-subsets algorithm based on separable quadratic surrogates for regularized image reconstruction in X-ray CT}, 
	year={2011},
	volume={},
	number={},
	pages={1134-1137},
	doi={10.1109/ISBI.2011.5872601}
}

@ARTICLE{ramani_splitting_2012,
	author={Ramani, Sathish and Fessler, Jeffrey A.},
	journal={IEEE Transactions on Medical Imaging}, 
	title={A Splitting-Based Iterative Algorithm for Accelerated Statistical X-Ray CT Reconstruction},
	year={2012},
	volume={31},
	number={3},
	pages={677-688},
	doi={10.1109/TMI.2011.2175233}
}

@ARTICLE{kamphuis_accelerated_1998,
	author={Kamphuis, C. and Beekman, F.J.},
	journal={IEEE Transactions on Medical Imaging}, 
	title={Accelerated iterative transmission CT reconstruction using an ordered subsets convex algorithm},
	year={1998},
	volume={17},
	number={6},
	pages={1101-1105},
	doi={10.1109/42.746730}
}

@ARTICLE{fessler_conjugate_1999,
	author={Fessler, J.A. and Booth, S.D.},
	journal={IEEE Transactions on Image Processing}, 
	title={Conjugate-gradient preconditioning methods for shift-variant PET image reconstruction},
	year={1999},
	volume={8},
	number={5},
	pages={688-699},
	doi={10.1109/83.760336}
}

@ARTICLE{kaczmarz_angenaeherte_1937,
	author={Kaczmarz, S.},
	journal={Bulletin International de l'Académie Polonaise des Sciences et des Lettres A}, 
	title={Angenäherte Auflösung von Systemen linearer Gleichungen},
	year={1937},
	pages={355-357},
}

@article{zhao_convolutional_2019,
	doi = {10.1002/mp.13666},
	url = {https://doi.org/10.1002%2Fmp.13666},
	year = 2019,
	month = jul,
	publisher = {Wiley},
	volume = {46},
	number = {9},
	pages = {3941--3950},
	author = {Tingting Zhao and Michael McNitt-Gray and Dan Ruan},
	title = {A convolutional neural network for ultra-low-dose {CT} denoising and emphysema screening},
	journal = {Medical Physics}
}

@ARTICLE{chen_low-dose_2017,
	author={Chen, Hu and Zhang, Yi and Kalra, Mannudeep K. and Lin, Feng and Chen, Yang and Liao, Peixi and Zhou, Jiliu and Wang, Ge},
	journal={IEEE Transactions on Medical Imaging}, 
	title={Low-Dose CT With a Residual Encoder-Decoder Convolutional Neural Network}, 
	year={2017},
	volume={36},
	number={12},
	pages={2524-2535},
	doi={10.1109/TMI.2017.2715284}
}

@article{liu_low-dose_2018,
	title = {Low-dose CT restoration via stacked sparse denoising autoencoders},
	journal = {Neurocomputing},
	volume = {284},
	pages = {80-89},
	year = {2018},
	issn = {0925-2312},
	doi = {10.1016/j.neucom.2018.01.015},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231218300316},
	author = {Yan Liu and Yi Zhang},
	keywords = {Low-dose CT, Deep learning, Image restoration, Autoencoder},
	abstract = {To improve the imaging quality of low-dose computed tomography (CT) images, a deep learning based method for low-dose CT restoration is presented in this paper. Stacked sparse denoising autoencoders, which were designed originally for training noisy samples, are adopted to construct the architecture. Experimental results demonstrate that the proposed model outperforms several state-of-the-art methods, including total variation based projection on convex sets (TV-POCS), dictionary learning, block-matching 3D (BM3D), convolutional denoising autoencoders (CDA) and U-Net based residual convolutional neural network (KAIST-Net), both qualitatively and quantitatively. The proposed method is not only capable of suppressing noise but also recovering structural details. Furthermore, once the network is trained offline, the processing speed for target low-dose images is much faster than other methods.}
}

@article{yang_improving_2017,
	doi = {10.1109/access.2017.2766438},
	url = {https://doi.org/10.1109%2Faccess.2017.2766438},
	year = 2017,
	publisher = {Institute of Electrical and Electronics Engineers},
	volume = {5},
	pages = {24698--24705},
	author = {Wei Yang and Huijuan Zhang and Jian Yang and Jiasong Wu and Xiangrui Yin and Yang Chen and Huazhong Shu and Limin Luo and Gouenou Coatrieux and Zhiguo Gui and Qianjin Feng},
	title = {Improving Low-Dose {CT} Image Using Residual Convolutional Network},
	journal = {{IEEE} Access}
}
